{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python3.9.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# БИБЛИОТЕКИ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Установка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in ./.venv/lib/python3.9/site-packages (24.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_community in ./.venv/lib/python3.9/site-packages (0.2.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.9/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.9/site-packages (from langchain_community) (3.10.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in ./.venv/lib/python3.9/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.12 in ./.venv/lib/python3.9/site-packages (from langchain_community) (0.2.12)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in ./.venv/lib/python3.9/site-packages (from langchain_community) (0.2.28)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in ./.venv/lib/python3.9/site-packages (from langchain_community) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.9/site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in ./.venv/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.9/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.9/site-packages (from langchain<0.3.0,>=0.2.12->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.12->langchain_community) (2.20.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in ./.venv/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: langchain_openai in ./.venv/lib/python3.9/site-packages (0.1.20)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.26 in ./.venv/lib/python3.9/site-packages (from langchain_openai) (0.2.28)\n",
      "Collecting openai<2.0.0,>=1.32.0 (from langchain_openai)\n",
      "  Using cached openai-1.38.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./.venv/lib/python3.9/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (6.0.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.1.96)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (24.1)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.26->langchain_openai) (4.12.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.4.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./.venv/lib/python3.9/site-packages (from openai<2.0.0,>=1.32.0->langchain_openai) (4.66.5)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./.venv/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.7.24)\n",
      "Requirement already satisfied: requests>=2.26.0 in ./.venv/lib/python3.9/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (3.7)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./.venv/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in ./.venv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./.venv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.26->langchain_openai) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.26->langchain_openai) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.2.2)\n",
      "Using cached openai-1.38.0-py3-none-any.whl (335 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 0.28.0\n",
      "    Uninstalling openai-0.28.0:\n",
      "      Successfully uninstalled openai-0.28.0\n",
      "Successfully installed openai-1.38.0\n",
      "Requirement already satisfied: langchain in ./.venv/lib/python3.9/site-packages (0.2.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./.venv/lib/python3.9/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./.venv/lib/python3.9/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./.venv/lib/python3.9/site-packages (from langchain) (3.10.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in ./.venv/lib/python3.9/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.27 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.28)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./.venv/lib/python3.9/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./.venv/lib/python3.9/site-packages (from langchain) (0.1.96)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./.venv/lib/python3.9/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./.venv/lib/python3.9/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./.venv/lib/python3.9/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./.venv/lib/python3.9/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./.venv/lib/python3.9/site-packages (from langchain-core<0.3.0,>=0.2.27->langchain) (4.12.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./.venv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./.venv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in ./.venv/lib/python3.9/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./.venv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.27->langchain) (3.0.0)\n",
      "Collecting openai==0.28\n",
      "  Using cached openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.9/site-packages (from openai==0.28) (2.32.3)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.9/site-packages (from openai==0.28) (4.66.5)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.9/site-packages (from openai==0.28) (3.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (2.3.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (24.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.9/site-packages (from aiohttp->openai==0.28) (4.0.3)\n",
      "Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
      "Installing collected packages: openai\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.38.0\n",
      "    Uninstalling openai-1.38.0:\n",
      "      Successfully uninstalled openai-1.38.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-openai 0.1.20 requires openai<2.0.0,>=1.32.0, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed openai-0.28.0\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-docx in ./.venv/lib/python3.9/site-packages (1.1.2)\n",
      "Requirement already satisfied: lxml>=3.1.0 in ./.venv/lib/python3.9/site-packages (from python-docx) (5.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in ./.venv/lib/python3.9/site-packages (from python-docx) (4.12.2)\n",
      "Requirement already satisfied: faiss-cpu in ./.venv/lib/python3.9/site-packages (1.8.0.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.0 in ./.venv/lib/python3.9/site-packages (from faiss-cpu) (1.26.4)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.9/site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: colorama in ./.venv/lib/python3.9/site-packages (0.4.6)\n",
      "Requirement already satisfied: python-magic in ./.venv/lib/python3.9/site-packages (0.4.27)\n",
      "Requirement already satisfied: docx2txt in ./.venv/lib/python3.9/site-packages (0.8)\n",
      "Requirement already satisfied: html2text in ./.venv/lib/python3.9/site-packages (2024.2.26)\n",
      "/bin/bash: строка 1: p1ip: команда не найдена\n",
      "Requirement already satisfied: google in ./.venv/lib/python3.9/site-packages (3.0.0)\n",
      "Requirement already satisfied: beautifulsoup4 in ./.venv/lib/python3.9/site-packages (from google) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.9/site-packages (from beautifulsoup4->google) (2.5)\n",
      "Requirement already satisfied: pdfminer.six in ./.venv/lib/python3.9/site-packages (20240706)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in ./.venv/lib/python3.9/site-packages (from pdfminer.six) (3.3.2)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in ./.venv/lib/python3.9/site-packages (from pdfminer.six) (43.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.9/site-packages (from cryptography>=36.0.0->pdfminer.six) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six) (2.22)\n",
      "Requirement already satisfied: google-auth in ./.venv/lib/python3.9/site-packages (2.32.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.9/site-packages (from google-auth) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.9/site-packages (from google-auth) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.9/site-packages (from google-auth) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.0)\n",
      "Requirement already satisfied: pdfminer in ./.venv/lib/python3.9/site-packages (20191125)\n",
      "Requirement already satisfied: pycryptodome in ./.venv/lib/python3.9/site-packages (from pdfminer) (3.20.0)\n",
      "Requirement already satisfied: gspread in ./.venv/lib/python3.9/site-packages (6.1.2)\n",
      "Requirement already satisfied: google-auth>=1.12.0 in ./.venv/lib/python3.9/site-packages (from gspread) (2.32.0)\n",
      "Requirement already satisfied: google-auth-oauthlib>=0.4.1 in ./.venv/lib/python3.9/site-packages (from gspread) (1.2.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.9/site-packages (from google-auth>=1.12.0->gspread) (5.4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.9/site-packages (from google-auth>=1.12.0->gspread) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.9/site-packages (from google-auth>=1.12.0->gspread) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in ./.venv/lib/python3.9/site-packages (from google-auth-oauthlib>=0.4.1->gspread) (2.0.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in ./.venv/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.12.0->gspread) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in ./.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.2.2)\n",
      "Requirement already satisfied: requests>=2.0.0 in ./.venv/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib>=0.4.1->gspread) (2024.7.4)\n",
      "Requirement already satisfied: oauth2client in ./.venv/lib/python3.9/site-packages (4.1.3)\n",
      "Requirement already satisfied: httplib2>=0.9.1 in ./.venv/lib/python3.9/site-packages (from oauth2client) (0.22.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in ./.venv/lib/python3.9/site-packages (from oauth2client) (0.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in ./.venv/lib/python3.9/site-packages (from oauth2client) (0.4.0)\n",
      "Requirement already satisfied: rsa>=3.1.4 in ./.venv/lib/python3.9/site-packages (from oauth2client) (4.9)\n",
      "Requirement already satisfied: six>=1.6.1 in ./.venv/lib/python3.9/site-packages (from oauth2client) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.9/site-packages (from httplib2>=0.9.1->oauth2client) (3.1.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./.venv/lib/python3.9/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.9/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: Pillow in ./.venv/lib/python3.9/site-packages (10.4.0)\n",
      "Requirement already satisfied: fitz in ./.venv/lib/python3.9/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: configobj in ./.venv/lib/python3.9/site-packages (from fitz) (5.0.8)\n",
      "Requirement already satisfied: configparser in ./.venv/lib/python3.9/site-packages (from fitz) (7.0.0)\n",
      "Requirement already satisfied: httplib2 in ./.venv/lib/python3.9/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in ./.venv/lib/python3.9/site-packages (from fitz) (5.2.1)\n",
      "Requirement already satisfied: nipype in ./.venv/lib/python3.9/site-packages (from fitz) (1.8.6)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.9/site-packages (from fitz) (1.26.4)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.9/site-packages (from fitz) (2.2.2)\n",
      "Requirement already satisfied: pyxnat in ./.venv/lib/python3.9/site-packages (from fitz) (1.6.2)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.9/site-packages (from fitz) (1.13.1)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.9/site-packages (from configobj->fitz) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./.venv/lib/python3.9/site-packages (from httplib2->fitz) (3.1.2)\n",
      "Requirement already satisfied: packaging>=17 in ./.venv/lib/python3.9/site-packages (from nibabel->fitz) (24.1)\n",
      "Requirement already satisfied: click>=6.6.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (8.1.7)\n",
      "Requirement already satisfied: networkx>=2.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (3.2.1)\n",
      "Requirement already satisfied: prov>=1.5.2 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (3.19.2)\n",
      "Requirement already satisfied: traits!=5.0,<6.4,>=4.6 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: filelock>=3.0.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (3.15.4)\n",
      "Requirement already satisfied: etelemetry>=0.2.0 in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion in ./.venv/lib/python3.9/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.9/site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.9/site-packages (from pandas->fitz) (2024.1)\n",
      "Requirement already satisfied: lxml>=4.3 in ./.venv/lib/python3.9/site-packages (from pyxnat->fitz) (5.2.2)\n",
      "Requirement already satisfied: requests>=2.20 in ./.venv/lib/python3.9/site-packages (from pyxnat->fitz) (2.32.3)\n",
      "Requirement already satisfied: pathlib>=1.0 in ./.venv/lib/python3.9/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: ci-info>=0.2 in ./.venv/lib/python3.9/site-packages (from etelemetry>=0.2.0->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in ./.venv/lib/python3.9/site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->pyxnat->fitz) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->pyxnat->fitz) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->pyxnat->fitz) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.9/site-packages (from requests>=2.20->pyxnat->fitz) (2024.7.4)\n",
      "Collecting PyMuPDF\n",
      "  Using cached PyMuPDF-1.24.9-cp39-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.9 (from PyMuPDF)\n",
      "  Using cached PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Using cached PyMuPDF-1.24.9-cp39-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "Using cached PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "Installing collected packages: PyMuPDFb, PyMuPDF\n",
      "  Attempting uninstall: PyMuPDFb\n",
      "    Found existing installation: PyMuPDFb 1.24.9\n",
      "    Uninstalling PyMuPDFb-1.24.9:\n",
      "      Successfully uninstalled PyMuPDFb-1.24.9\n",
      "  Attempting uninstall: PyMuPDF\n",
      "    Found existing installation: PyMuPDF 1.24.9\n",
      "    Uninstalling PyMuPDF-1.24.9:\n",
      "      Successfully uninstalled PyMuPDF-1.24.9\n",
      "Successfully installed PyMuPDF-1.24.9 PyMuPDFb-1.24.9\n",
      "Requirement already satisfied: PyMuPDF in ./.venv/lib/python3.9/site-packages (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in ./.venv/lib/python3.9/site-packages (from PyMuPDF) (1.24.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community\n",
    "!pip install langchain_openai\n",
    "!pip install langchain\n",
    "!pip install openai==0.28 # ==1.30.05\n",
    "!pip install python-dotenv\n",
    "!pip install python-docx\n",
    "!pip install faiss-cpu\n",
    "!pip install colorama\n",
    "!pip install python-magic\n",
    "!pip install docx2txt\n",
    "!pip install html2text\n",
    "!p1ip install gdown\n",
    "!pip install google\n",
    "!pip install pdfminer.six\n",
    "!pip install google-auth\n",
    "!pip install pdfminer\n",
    "!pip install gspread\n",
    "!pip install oauth2client\n",
    "# !pip install openai==1.32\n",
    "!pip install pandas\n",
    "!pip install Pillow\n",
    "!pip install fitz\n",
    "!pip install --force-reinstall PyMuPDF\n",
    "!pip install PyMuPDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Импорт"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import yaml\n",
    "import re\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import openai\n",
    "import os as operating_system\n",
    "from docx import Document as DocxDocument\n",
    "from docx2txt import process\n",
    "import docx\n",
    "import docx2txt\n",
    "import pickle\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import requests\n",
    "from langchain.vectorstores import FAISS\n",
    "import magic\n",
    "import html2text\n",
    "from langchain.schema import Document\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "import gspread\n",
    "import pandas as pd\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "import pdfminer\n",
    "from urllib.parse import urlparse, unquote\n",
    "import shutil\n",
    "from bs4 import BeautifulSoup\n",
    "from google.oauth2.service_account import Credentials\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "# import gdown\n",
    "from builtins import ImportError, ValueError, KeyError\n",
    "import datetime\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "\n",
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.9/site-packages (1.0.1)\n",
      "51\n",
      "Ключ GPT_SECRET_KEY загружен\n"
     ]
    }
   ],
   "source": [
    "# API OPENAI\n",
    "!pip install python-dotenv\n",
    "# !pip install openai==1.32\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"/media/user/Work/VSCode/GPT/0_env_instructions/.env\")\n",
    "# передаем секретные данные в переменные\n",
    "GPT_SECRET_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# передаем секретный токен chatgpt\n",
    "openai.api_key = GPT_SECRET_KEY\n",
    "print(len(GPT_SECRET_KEY))\n",
    "# Проверка загрузки ключа\n",
    "if not GPT_SECRET_KEY:\n",
    "    print(\"Ключ GPT_SECRET_KEY не считался\")\n",
    "else:\n",
    "    print(\"Ключ GPT_SECRET_KEY загружен\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - проверка существования переменной и её создание на случай её отсутствия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Проверка существования переменной и её создание на случай её отсутствия\n",
    "# try:\n",
    "#     print(f\"Существует переменная 'var'. Её значение: {var1}\") # пробуем провести операцию с указанной переменной.\n",
    "# except NameError: # Если операция с переменной не удается, то выполняем действия ниже: объявляем переменную и её значение\n",
    "#     var1 = 123\n",
    "#     print(f\"Переменной 'var1' не существует\\nОбъявлена переменная 'var1' со значением: {var1}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FUN для получения значения ключа из файла settings.yml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для получения значения ключа из файла settings.yml\n",
    "def get_environment_value(file_path:str, name_key:str): # file_path - путь к файлу настроек, включая название файла settings.yml / name_key = \"название переменной\" в кавычках. В settngs.yml: название перменной: \"значение\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        config = yaml.safe_load(file)\n",
    "        return config.get(name_key)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FUN очистки папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция очистки папки\n",
    "# import os\n",
    "# import shutil\n",
    "\n",
    "def clear_folder(folder_path): # folder_path - Путь к папке, которую нужно очистить\n",
    "    if os.path.exists(folder_path):\n",
    "        shutil.rmtree(folder_path)  # Удаляет папку и все ее содержимое\n",
    "        os.makedirs(folder_path)  # Создает пустую папку заново"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - CLASS оформление текста цветом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bcolors256:\n",
    "    RESET = '\\033[0m'  # Сброс всех эффектов\n",
    "\n",
    "    @staticmethod\n",
    "    def fg(color_code):\n",
    "        \"\"\"Возвращает строку с цветом текста\"\"\"\n",
    "        return f'\\033[38;5;{color_code}m'\n",
    "\n",
    "    @staticmethod\n",
    "    def bg(color_code):\n",
    "        \"\"\"Возвращает строку с цветом фона\"\"\"\n",
    "        return f'\\033[48;5;{color_code}m'\n",
    "\n",
    "    @staticmethod\n",
    "    def bold():\n",
    "        \"\"\"Возвращает строку для жирного текста\"\"\"\n",
    "        return '\\033[1m'\n",
    "\n",
    "    @staticmethod\n",
    "    def underline():\n",
    "        \"\"\"Возвращает строку для подчеркнутого текста\"\"\"\n",
    "        return '\\033[4m'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[48;5;228m\u001b[38;5;18m\u001b[1m\u001b[4m Фон-\"bg\", шрифт-\"fg\" \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Пример использования 256 цветов: bg - фон / fg - шрифт с жирным и подчеркнутым текстом\n",
    "print(f'{bcolors256.bg(228)}{bcolors256.fg(18)}{bcolors256.bold()}{bcolors256.underline()} Фон-\"bg\", шрифт-\"fg\" {bcolors256.RESET}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FUN копирования директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files_in_directory(source_dir: str, target_dir: str):\n",
    "    # Убедимся, что целевая директория существует\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "    \n",
    "    for filename in os.listdir(source_dir):\n",
    "        source_path = os.path.join(source_dir, filename)\n",
    "        target_path = os.path.join(target_dir, filename)\n",
    "        \n",
    "        # Проверка, что это файл, а не директория\n",
    "        if os.path.isfile(source_path):\n",
    "            if not os.path.isfile(target_path):\n",
    "                shutil.copy(source_path, target_path)\n",
    "                print(f\"✅ Файл успешно скопирован из {source_path} в {target_path}.\")\n",
    "            else:\n",
    "                print(f\"🔵 Файл по пути {target_path} уже существует. Копирование пропущено.\")\n",
    "        else:\n",
    "            print(f\"🔵 {source_path} не является файлом. Копирование пропущено.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -копирование баз faiss base / olther / contacts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### -- base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-03.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-03_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-28.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-281.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-281_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-28_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-395.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-395_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-397.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-397_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-450.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-450_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM301.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM301_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM302.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM303.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM303_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M04.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M04_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M12.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M12_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M211.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M211_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M22.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M22_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M25.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M251.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M251_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M252.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M252_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M253_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M25_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M26.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M26_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M29.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M291.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M291_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M29_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M30.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M30_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M31.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M31_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M34.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M34_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M35.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M36.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M36_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M37.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M37_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M38.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M38_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M398.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M398_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M399.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M399_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4511.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4511_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4512.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4512_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4516.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-IHM302_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M253.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M35_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M4516_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-P350.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M50.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M50_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M70.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M70_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M90.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M902.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M902_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M90_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M95.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M95_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M96.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-M96_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-MD200.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-MD200_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND RMC-P350_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M224S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M224S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M225S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M225S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M226S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M226S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M227S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M227S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M40S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M40S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M800S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M800S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M903S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M903S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M92S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker M92S_data.pkl уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker MC100S.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS/REDMOND SkyCooker MC100S_data.pkl уже существует. Копирование пропущено.\n"
     ]
    }
   ],
   "source": [
    "# Копирование баз\n",
    "source_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/1_DB/PROJECT/DATA/DB_FAISS\"\n",
    "target_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS\"\n",
    "copy_files_in_directory(source_directory, target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - olther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_OLTHER/data_google_olther.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_OLTHER/data_google_olther_data.pkl уже существует. Копирование пропущено.\n"
     ]
    }
   ],
   "source": [
    "# Копирование баз\n",
    "source_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/1_DB/PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "target_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "copy_files_in_directory(source_directory, target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - contacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_CONTACTS/data_google_contacts.faiss уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути /media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_CONTACTS/data_google_contacts_data.pkl уже существует. Копирование пропущено.\n"
     ]
    }
   ],
   "source": [
    "# Копирование баз\n",
    "source_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/1_DB/PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "target_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/2_RUN/PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "copy_files_in_directory(source_directory, target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### - images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M253.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M50.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-03.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-28.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-281.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-395.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-397.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-450.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-IHM301.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-IHM302.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-IHM303.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M04.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M12.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M211.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M22.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M25.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M251.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M252.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M26.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M29.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M291.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M30.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M31.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M34.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M35.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M36.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M37.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M38.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M398.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M399.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M4511.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M4512.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M4516.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M70.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M90.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M902.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M95.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-M96.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-MD200.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND RMC-P350.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M224S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M225S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M226S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M227S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M40S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M800S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M903S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker M92S.jpg уже существует. Копирование пропущено.\n",
      "🔵 Файл по пути PROJECT/DATA/IMAGES/REDMOND SkyCooker MC100S.jpg уже существует. Копирование пропущено.\n"
     ]
    }
   ],
   "source": [
    "# Копирование изображений\n",
    "source_directory = \"/media/user/Work/VSCode/GPT/11_DIPLOM/1_BACKEND/1_DB/PROJECT/DATA/IMAGES\"\n",
    "target_directory = \"PROJECT/DATA/IMAGES\"\n",
    "copy_files_in_directory(source_directory, target_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS BASIC not SUM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN - кластеризатор вопроса  на подвопросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1. Сколько программ есть у мультиварки RMC-03?', '2. Сколько программ есть у мультиварки RMC-28?']\n"
     ]
    }
   ],
   "source": [
    "# Функция - кластеризатор вопроса  на подвопросы\n",
    "def question_clusterizer(question):\n",
    "    # question = \"Что такое мультиварка rmc-03, есть ли она в наличии и сколько у неё программ? Сколько стоит?\"\n",
    "\n",
    "    # Промт для кластеризации вопроса\n",
    "    prompt_syst = f\"\"\"\n",
    "    Пожалуйста, разбей вопрос на подвопросы, учитывая конкретные сущности и аспекты.\n",
    "    Формулируй кратко, максимально близко к вопросу, не придумывая ничего от себя.\n",
    "    Если можно сформулировать одним вопросом, формулируй ордним вопросом.\n",
    "    Не нужно расписывать один вопрос на несколько вариантов.\n",
    "    Например предложения: '1. Как найти магазин? ', '2. Как узнать адрес магазина? ', '3. Как узнать расположение магазина на карте?' и подобные - это один вопрос: 'Как узнать адрес магазина?'\n",
    "    Формулируй точно по вопросу\n",
    "    Вопрос: \"{question}\"\n",
    "    \"\"\"\n",
    "    prompt_user = f\"\"\"\n",
    "    Разбей вопрос на подвопросы, учитывая конкретные сущности и аспекты. Вопрос: '{question}'\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", # 4o\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": prompt_syst},\n",
    "            {\"role\": \"user\", \"content\": prompt_user}\n",
    "        ],\n",
    "            # {\"role\": \"user\", \"content\": \"Сколько программ у мультиврки rmc-03 и у rmc28?\"},\n",
    "            # {\"role\": \"assistant\", \"content\": \"\"\"\n",
    "            #  Сколько программ у мультиврки rmc-03?\n",
    "            #  Сколько программ у мультиврки rmc-28?\"\"\"},\n",
    "        max_tokens=150,\n",
    "        n=1,\n",
    "        stop=None,\n",
    "        temperature=0,\n",
    "    )\n",
    "    # Извлечение ответа и преобразование его в список\n",
    "    response_content = response['choices'][0]['message']['content'].strip()\n",
    "    # Преобразование строки в список по разделителю новой строки\n",
    "    clustered_questions = [q.strip() for q in response_content.split('\\n') if q.strip()]\n",
    "    return clustered_questions\n",
    "\n",
    "queston = \"Скольок программ у мультиварки rmc-03, а у rmc-28&\"\n",
    "# Получение кластеризованных подвопросов\n",
    "clustered_questions = question_clusterizer(queston)\n",
    "print(clustered_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for topic in clustered_questions:\n",
    "#     answer_gpt(topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN ретривер вопроса (Мультиварка / Адрес / Прочее)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_gpt_tems(queston, prompt_system=\"Ты профессиональный аналитик текстов, ты понимаешь, когда речь идет о технических характеристиках мультиварки, а когда общие вопросы\"): # self, \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": \"Сколько программ имеет мультиварка?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Мультиварка\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "         Определи тему вопроса клиента. \n",
    "         Если вопрос клиента касается технических параметров мультиварки или стоимости, ответь одним словом 'Мультиварка'. \n",
    "         Если клиент спрашивает про адрес магазина, то ответь одним словом 'Адрес'. \n",
    "         Если вопрос клиента касается изображения товара, ответь одним словом 'Изображение'.\n",
    "         В остальных случаях ответь одним словом 'Прочее'. Вопрос клиента: \\n{queston}\"\"\"},\n",
    "    ]\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\", # \"gpt-4o\" / \"gpt-4-0613\" / \"gpt-3.5-turbo\"\n",
    "        messages=messages,\n",
    "        temperature=0.7\n",
    "    )\n",
    "\n",
    "    answer_llm_analiz_topic = completion.choices[0].message['content']\n",
    "    # print(\"\\n\\n***\\n📲 Вопрос клиента: \", queston)\n",
    "    # print(\"📢 Ответ от llm: \", answer_llm_analiz_topic, \"\\n\")\n",
    "    return answer_llm_analiz_topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN ретривер моделей мультиварок (определяет модель)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Проверка\n",
      " - Вопрос: Сколько программ у мультиварки rmc 03\n",
      " - Ответ llm:\n",
      "   - REDMOND RMC-03\n"
     ]
    }
   ],
   "source": [
    "def retriever_gpt_model(queston, prompt_system=\"\"\"\n",
    "Ты профессиональный аналитик текстов, ты понимаешь о какой конкретно модели мультиварки идет речь.\n",
    "Отвечай только названием типа 'REDMOND RMC-03'.\n",
    "К названию ничего не прибавляй\"\"\"): # self, \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": \"Сколько программ имеет мультиварка rmc 03?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"REDMOND RMC-03\"},\n",
    "        {\"role\": \"user\", \"content\": \"Сколько стоит rmc 28?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"REDMOND RMC-28\"},\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "         Определи модель мультиварки по вопросу клиента. \n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-03'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-28'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-281'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-395'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-397'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-450'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-IHM301'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-IHM302'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-IHM303'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M04'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M12'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M211'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M22'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M25'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M251'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M252'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M253'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M26'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M29'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M291'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M30'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M31'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M34'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M35'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M36'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M37'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M38'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M398'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M399'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M4511'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M4512'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M4516'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M50'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M70'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M90'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M902'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M95'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M96'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-MD200'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-P350'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M224S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M225S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M226S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M227S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M40S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M800S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M903S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-M92S'.\n",
    "         Если в вопросе клиента есть упоминание RMC-03, то ответь: 'REDMOND RMC-MC100S'.\n",
    "         Если определить модель не удалось, ответь 'none'.\n",
    "         Вопрос клиента: \\n{queston}\"\"\"},\n",
    "    ]\n",
    "    # print(\"📡 OpenAI: messages, отправляемый в LLM: \\n\", messages)\n",
    "\n",
    "    # if verbose: \n",
    "    #     print('\\n ===========================================: ')\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\", # \"gpt-4o\" / \"gpt-4-0613\" / \"gpt-3.5-turbo\" / \"gpt-4-0613\"\n",
    "        messages=messages,\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    answer_llm_analiz_topic = completion.choices[0].message['content']\n",
    "    # print(\"\\n\\n***\\n📲 Вопрос клиента: \", queston)\n",
    "    # print(f\"📢 Ответ от llm, модель: \\n {answer_llm_analiz_topic}\")\n",
    "    return answer_llm_analiz_topic\n",
    "\n",
    "\n",
    "queston = \"Сколько программ у мультиварки rmc 03\"\n",
    "answer_model = retriever_gpt_model(queston)\n",
    "print(f\"Проверка\\n - Вопрос: {queston}\\n - Ответ llm:\\n   - {answer_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FUN: Answer: чанки и ответ LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pickle\n",
    "import openai\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# Ответ LLM\n",
    "def answer_oai_1(prompt_system, path_db_faiss, topic, db_name, verbose=0):\n",
    "\n",
    "    # ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ --------------------------------------------\n",
    "\n",
    "    score_threshold = 0.7\n",
    "\n",
    "    # Загрузка FAISS индекса\n",
    "    def load_faiss_index(file_path):\n",
    "        return faiss.read_index(file_path)\n",
    "\n",
    "    # Загрузка векторов и текстов чанков\n",
    "    def load_data(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data['chunks'] #, data['vectors']\n",
    "\n",
    "    # Преобразование вопроса в векторное представление\n",
    "    def embed_question(question, embeddings):\n",
    "        return np.array(embeddings.embed_documents([question]), dtype='float32')\n",
    "\n",
    "    # Поиск релевантных чанков\n",
    "    def search_relevant_chunks(index, question_vector, top_k=4):\n",
    "        distances, indices = index.search(question_vector, top_k)\n",
    "        return distances[0], indices[0]\n",
    "\n",
    "\n",
    "    def find_relevant_chunks(path_db_faiss, topic, db_name, score_threshold=0.7):\n",
    "        db_path = os.path.join(path_db_faiss, db_name + '.faiss')\n",
    "        data_path = os.path.join(path_db_faiss, db_name + '_data.pkl')\n",
    "        db_Availability:bool = False\n",
    "        # Проверка наличия файлов\n",
    "        if not os.path.exists(db_path) or not os.path.exists(data_path):\n",
    "            db_Availability = False\n",
    "            relevant_chunks = []\n",
    "            return relevant_chunks, db_Availability\n",
    "        else:\n",
    "            db_Availability = True\n",
    "\n",
    "        # Загрузка FAISS индекса\n",
    "        index = load_faiss_index(db_path)\n",
    "        \n",
    "        # Загрузка векторов и текстов чанков\n",
    "        chunks = load_data(data_path)  # , vectors\n",
    "        \n",
    "        # Инициализация модели для эмбеддингов\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "        # Преобразование вопроса в векторное представление\n",
    "        question_vector = embed_question(topic, embeddings)\n",
    "        \n",
    "        # Поиск релевантных чанков\n",
    "        distances, relevant_indices = search_relevant_chunks(index, question_vector)\n",
    "        \n",
    "        # Фильтрация релевантных чанков по порогу схожести\n",
    "        relevant_chunks = []\n",
    "        for distance, idx in zip(distances, relevant_indices):\n",
    "            similarity_score = 1 / (1 + distance)  # Преобразование расстояния в схожесть\n",
    "            if similarity_score >= score_threshold:\n",
    "                relevant_chunks.append(chunks[idx])\n",
    "\n",
    "        return relevant_chunks, db_Availability\n",
    "\n",
    "    \n",
    "    relevant_chunks, db_Availability  = find_relevant_chunks(path_db_faiss, topic, db_name)\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": \"Какой адрес вашего сайта?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Адрес нашего сайта: https://redmond.company\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Ответь на вопрос клиента. Не упоминай документ с информацией для ответа клиенту в ответе. Документ с информацией для ответа клиенту: {relevant_chunks}\\n\\nВопрос клиента: \\n{topic}\"},\n",
    "    ]\n",
    "    # print(\"📡 OpenAI: messages, отправляемый в LLM: \\n\", messages)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n ===========================================: ')\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", # \"gpt-4o\" / \"gpt-4-0613\" / \"gpt-3.5-turbo\"\n",
    "        messages=messages,\n",
    "        temperature=0.4\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message['content']\n",
    "    # print(\"\\n***\\n\\n📢 Ответ от llm: \", answer, \"\\n\")\n",
    "    return answer, relevant_chunks, db_Availability\n",
    "\n",
    "# path_db_faiss = \"PROJECT/DATA/DB_FAISS\"\n",
    "# db_name = \"REDMOND RMC-03\"\n",
    "# topic = \"Сколько нужно времени для приготовления Филе свинины/говядины (кубиками по 1,5-2 см) в мультиварке REDMOND RMC-03?\"\n",
    "# system_mult = \"\"\"Ты отлично разбираешься в мультиварках. Пркрасно знаешь все характеристики мультиварки.\n",
    "# Ты особенно внимателен к цифрам и названиями.\n",
    "# Очень подробно и детально ответь на вопрос пользователя, опираясь точно на документ с информацией для ответа клиенту.\n",
    "# Не придумывай ничего от себя. Не ссылайся на сами отрывки документ с информацией для ответа, клиент о них ничего не должен знать.\n",
    "# \"\"\"\n",
    "# answer_oai_1(system_mult, path_db_faiss, topic, db_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ЗАПУСК ПРОВЕРКИ без _sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import yaml\n",
    "\n",
    "# def answer_gpt(question: str):\n",
    "#     # Функция чтения Promts\n",
    "#     def get_environment_value(file_path, name_key):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             config = yaml.safe_load(file)\n",
    "#             return config.get(name_key)\n",
    "    \n",
    "#     # Чтение значений ключа\n",
    "#     file_path = \"PROJECT/PROMTS/promts.yml\"\n",
    "#     system_mult_ = get_environment_value(file_path, \"system_mult\")\n",
    "#     system_shop_ = get_environment_value(file_path, \"system_shop\")\n",
    "#     system_cont_ = get_environment_value(file_path, \"system_cont\")\n",
    "    \n",
    "#     print(f\"****************************************\")\n",
    "#     print(f'{bcolors256.underline()}    ❓ Вопрос пользователя:  {bcolors256.bg(11)}{bcolors256.fg(0)}{bcolors256.bold()}{question}{bcolors256.RESET} ')\n",
    "    \n",
    "#     sub_questions = question_clusterizer(question)\n",
    "#     print(f'    Подвопросов: {len(sub_questions)}')\n",
    "#     print(f'    ❗❓ Подвопросы в вопросе пользователя: {bcolors256.bold()}  {sub_questions} {bcolors256.RESET}')\n",
    "    \n",
    "#     answer_all = []\n",
    "#     for sub_question in sub_questions:\n",
    "#         print(f'\\n    ---\\n    Обработка вопроса:  {bcolors256.bg(20)}{bcolors256.fg(11)}{bcolors256.bold()}  {sub_question} {bcolors256.RESET}')\n",
    "#         analitix = retriever_gpt_tems(sub_question)\n",
    "        \n",
    "#         # ответ\n",
    "#         if analitix == \"Мультиварка\":\n",
    "#             print(f\"\\n    Тема вопроса: {analitix}\")\n",
    "#             db_name = retriever_gpt_model(sub_question)\n",
    "#             if db_name != \"none\":\n",
    "#                 print(f\"    Определилась модель для ответа: {db_name}\")\n",
    "#                 path_db_faiss_mult = \"PROJECT/DATA/DB_FAISS\"\n",
    "#                 answer, relevant_chunks_0, db_Availability = answer_oai_1(system_mult_, path_db_faiss_mult, sub_question, db_name)\n",
    "#                 print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#                 print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#                 print(f\"    База найдена: {db_Availability}\")\n",
    "#                 answer_all.append(answer)\n",
    "#             else:\n",
    "#                 print(\"Не удалось определить модель мультиварки, повторите пожалуйста вопрос\")\n",
    "#                 continue  # Продолжаем обработку следующих подвопросов\n",
    "#         elif analitix == \"Адрес\":\n",
    "#             print(f\"    Тема вопроса: {analitix}\")\n",
    "#             print(\"    Запрос адреса магазина\")\n",
    "#             path_db_faiss_shop = \"PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "#             db_name_shop = \"data_google_olther\"\n",
    "#             answer, relevant_chunks_0, db_Availability = answer_oai_1(system_shop_, path_db_faiss_shop, sub_question, db_name_shop)\n",
    "#             print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#             print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#             answer_all.append(answer)\n",
    "        \n",
    "#         else:\n",
    "#             print(\"    Контактная информация\")\n",
    "#             print(f\"    Тема вопроса: {analitix}\")\n",
    "#             path_db_faiss_cont = \"PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "#             db_name_contact = \"data_google_contacts\"\n",
    "#             answer, relevant_chunks_0, db_Availability = answer_oai_1(system_cont_, path_db_faiss_cont, sub_question, db_name_contact)\n",
    "#             print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#             print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#             answer_all.append(answer)\n",
    "    \n",
    "#     print(f\"\\n\\n****************************************\")\n",
    "#     print(f'answer_all: {answer_all}')  # Отладочный вывод списка ответов\n",
    "#     return answer_all  # Возвращаем список ответов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in ./.venv/lib/python3.9/site-packages (10.4.0)\n",
      "Requirement already satisfied: matplotlib in ./.venv/lib/python3.9/site-packages (3.9.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./.venv/lib/python3.9/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in ./.venv/lib/python3.9/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in ./.venv/lib/python3.9/site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in ./.venv/lib/python3.9/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./.venv/lib/python3.9/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in ./.venv/lib/python3.9/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in ./.venv/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow\n",
    "import yaml\n",
    "!pip install matplotlib\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_gpt_answall(question: str):\n",
    "    answer_all = []\n",
    "    def get_environment_value(file_path, name_key):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config.get(name_key)\n",
    "    \n",
    "    file_path = \"PROJECT/PROMTS/promts.yml\"\n",
    "    system_mult_ = get_environment_value(file_path, \"system_mult\")\n",
    "    system_shop_ = get_environment_value(file_path, \"system_shop\")\n",
    "    system_cont_ = get_environment_value(file_path, \"system_cont\")\n",
    "    \n",
    "    print(f\"****************************************\")\n",
    "    print(f'{bcolors256.underline()}    ❓ Вопрос пользователя:  {bcolors256.bg(11)}{bcolors256.fg(0)}{bcolors256.bold()}{question}{bcolors256.RESET} ')\n",
    "    \n",
    "    sub_questions = question_clusterizer(question)\n",
    "    print(f'    Подвопросов: {len(sub_questions)}')\n",
    "    print(f'    ❗❓ Подвопросы в вопросе пользователя: {bcolors256.bold()}  {sub_questions} {bcolors256.RESET}')\n",
    "    \n",
    "    for sub_question in sub_questions:\n",
    "        print(f'\\n    ---\\n    Обработка вопроса:  {bcolors256.bg(20)}{bcolors256.fg(11)}{bcolors256.bold()}  {sub_question} {bcolors256.RESET}')\n",
    "        analitix = retriever_gpt_tems(sub_question)\n",
    "        \n",
    "        if analitix == \"Мультиварка\":\n",
    "            print(f\"\\n    Тема вопроса: {analitix}\")\n",
    "            db_name = retriever_gpt_model(sub_question)\n",
    "            print(f\"    Определённая модель: {db_name}\")  # Логирование\n",
    "            if db_name != \"none\":\n",
    "                print(f\"    Определилась модель для ответа: {db_name}\")\n",
    "                path_db_faiss_mult = \"PROJECT/DATA/DB_FAISS\"\n",
    "                answer, relevant_chunks_0, db_Availability = answer_oai_1(system_mult_, path_db_faiss_mult, sub_question, db_name)\n",
    "                print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "                print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "                print(f\"    База найдена: {db_Availability}\")\n",
    "                answer_all.append(answer)\n",
    "            else:\n",
    "                print(\"Не удалось определить модель мультиварки, повторите пожалуйста вопрос\")\n",
    "                continue\n",
    "        \n",
    "        elif analitix == \"Изображение\":\n",
    "            print(f\"    Тема вопроса: {analitix}\")\n",
    "            print(\"    🌄 Запрос изобраения мультиварки\")\n",
    "            path_db_images = \"PROJECT/DATA/IMAGES/\"\n",
    "            db_image = retriever_gpt_model(sub_question)\n",
    "            print(f\"    Определённая модель: {db_image}\")\n",
    "            db_image = \"REDMOND RMC-03\"\n",
    "            # Путь к изображению\n",
    "            image_path = path_db_images + db_image + \".jpg\" # \"PROJECT/DATA/IMAGES/REDMOND RMC-03.jpg\"\n",
    "\n",
    "            # Проверяем, существует ли файл\n",
    "            if os.path.isfile(image_path):\n",
    "                # Загружаем изображение\n",
    "                img = Image.open(image_path)\n",
    "                # Отображаем изображение\n",
    "                plt.imshow(img)\n",
    "                plt.axis('off')  # Скрыть оси\n",
    "                plt.show()\n",
    "            else:\n",
    "                # Если файл не найден, выводим \"none\"\n",
    "                print(\"none\")\n",
    "\n",
    "\n",
    "        elif analitix == \"Адрес\":\n",
    "            print(f\"    Тема вопроса: {analitix}\")\n",
    "            print(\"    Запрос адреса магазина\")\n",
    "            path_db_faiss_shop = \"PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "            db_name_shop = \"data_google_olther\"\n",
    "            answer, relevant_chunks_0, db_Availability = answer_oai_1(system_shop_, path_db_faiss_shop, sub_question, db_name_shop)\n",
    "            print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "            print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "            answer_all.append(answer)\n",
    "        \n",
    "        else:\n",
    "            print(\"    Контактная информация\")\n",
    "            print(f\"    Тема вопроса: {analitix}\")\n",
    "            path_db_faiss_cont = \"PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "            db_name_contact = \"data_google_contacts\"\n",
    "            answer, relevant_chunks_0, db_Availability = answer_oai_1(system_cont_, path_db_faiss_cont, sub_question, db_name_contact)\n",
    "            print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "            print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "            answer_all.append(answer)\n",
    "    \n",
    "    print(f\"\\n\\n****************************************\")\n",
    "    print(f'answer_all: {answer_all}')  # Отладочный вывод списка ответов\n",
    "    return answer_all  # Возвращаем список ответов\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +++ RUN DIALOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************\n",
      "\u001b[4m    ❓ Вопрос пользователя:  \u001b[48;5;11m\u001b[38;5;0m\u001b[1mПокажи изрбражение мультиварки rmc-28\u001b[0m \n",
      "    Подвопросов: 1\n",
      "    ❗❓ Подвопросы в вопросе пользователя: \u001b[1m  ['Как выглядит мультиварка RMC-28?'] \u001b[0m\n",
      "\n",
      "    ---\n",
      "    Обработка вопроса:  \u001b[48;5;20m\u001b[38;5;11m\u001b[1m  Как выглядит мультиварка RMC-28? \u001b[0m\n",
      "    Тема вопроса: Изображение\n",
      "    🌄 Запрос изобраения мультиварки\n",
      "    Определённая модель: none\n",
      "none\n",
      "\n",
      "\n",
      "****************************************\n",
      "answer_all: []\n",
      "Список ответов:\n",
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "answer_all=[]\n",
    "questions = [\n",
    "    # \"Как найти ваш магазин, или можно позвонить?\",\n",
    "    # \"Сколько программ у мультиварки rmc-03 и у rmc-28\",\n",
    "    # \"Сколько rmc28 стоит?\",\n",
    "    \"Покажи изрбражение мультиварки rmc-28\"\n",
    "]\n",
    "\n",
    "for index, question in enumerate(questions, start=1):\n",
    "    answer = answer_gpt_answall(question)\n",
    "    answer_all.append(answer)\n",
    "    print(f\"Список ответов:\\n{answer_all}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCTIONS BASIC SUMARIZACION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FUN суммаризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Суммаризация\n",
    "summarized_history = \"\" # self.\n",
    "question_history = [] # self.\n",
    "\n",
    "# Самаризация\n",
    "def summarize_questions(dialog): # async # self, \n",
    "    # Применяем модель gpt-3.5-turbo-0613 для саммаризации вопросов\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"Если клиент назвал модель мультиварки, сохрани её название.\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": \"Если клиент назвал другую модель ультиварки, то запомни тольео последнюю модель мультиварки. Предыдущий диалог:\".join(dialog)}\n",
    "    ]\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\", # \"gpt-4o\" / \"gpt-4-0613\" / \"gpt-3.5-turbo\" / \"gpt-3.5-turbo-16k\"\n",
    "        messages=messages,\n",
    "        temperature=0.3,  # Используем более низкую температуру для более определенной суммаризации\n",
    "        max_tokens=1000  # Ограничиваем количество токенов для суммаризации\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - FUN answer llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ --------------------------------------------\n",
    "question_history = [] # self.\n",
    "\n",
    "# Ответ LLM\n",
    "def answer_oai_2_sum(prompt_system, path_db_faiss, topic, db_name, verbose=0):\n",
    "\n",
    "    # ВСПОМОГАТЕЛЬНЫЕ ФУНКЦИИ --------------------------------------------\n",
    "\n",
    "    score_threshold = 0.7\n",
    "\n",
    "    # Загрузка FAISS индекса\n",
    "    def load_faiss_index(file_path):\n",
    "        return faiss.read_index(file_path)\n",
    "\n",
    "    # Загрузка векторов и текстов чанков\n",
    "    def load_data(file_path):\n",
    "        with open(file_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        return data['chunks'] #, data['vectors']\n",
    "\n",
    "    # Преобразование вопроса в векторное представление\n",
    "    def embed_question(question, embeddings):\n",
    "        return np.array(embeddings.embed_documents([question]), dtype='float32')\n",
    "\n",
    "    # Поиск релевантных чанков\n",
    "    def search_relevant_chunks(index, question_vector, top_k=4):\n",
    "        distances, indices = index.search(question_vector, top_k)\n",
    "        return distances[0], indices[0]\n",
    "\n",
    "\n",
    "    def find_relevant_chunks(path_db_faiss, topic, db_name, score_threshold=0.7):\n",
    "        db_path = os.path.join(path_db_faiss, db_name + '.faiss')\n",
    "        data_path = os.path.join(path_db_faiss, db_name + '_data.pkl')\n",
    "        db_Availability:bool = False\n",
    "        # Проверка наличия файлов\n",
    "        if not os.path.exists(db_path) or not os.path.exists(data_path):\n",
    "            db_Availability = False\n",
    "            relevant_chunks = []\n",
    "            return relevant_chunks, db_Availability\n",
    "        else:\n",
    "            db_Availability = True\n",
    "\n",
    "        # Загрузка FAISS индекса\n",
    "        index = load_faiss_index(db_path)\n",
    "        \n",
    "        # Загрузка векторов и текстов чанков\n",
    "        chunks = load_data(data_path)  # , vectors\n",
    "        \n",
    "        # Инициализация модели для эмбеддингов\n",
    "        embeddings = OpenAIEmbeddings()\n",
    "        \n",
    "        # Преобразование вопроса в векторное представление\n",
    "        question_vector = embed_question(topic, embeddings)\n",
    "        \n",
    "        # Поиск релевантных чанков\n",
    "        distances, relevant_indices = search_relevant_chunks(index, question_vector)\n",
    "        \n",
    "        # Фильтрация релевантных чанков по порогу схожести\n",
    "        relevant_chunks = []\n",
    "        for distance, idx in zip(distances, relevant_indices):\n",
    "            similarity_score = 1 / (1 + distance)  # Преобразование расстояния в схожесть\n",
    "            if similarity_score >= score_threshold:\n",
    "                relevant_chunks.append(chunks[idx])\n",
    "\n",
    "        return relevant_chunks, db_Availability\n",
    "\n",
    "    \n",
    "    relevant_chunks, db_Availability  = find_relevant_chunks(path_db_faiss, topic, db_name)\n",
    "\n",
    "    print(f\"История на входе: {question_history}\")\n",
    "    # =====================================================================================\n",
    "    # Суммаризация\n",
    "    try:\n",
    "        # Пытаемся использовать переменную summarized_history\n",
    "        summarized_history\n",
    "    except NameError:\n",
    "        # Если переменная summarized_history не определена, возникает исключение NameError\n",
    "        # В блоке except создаём переменную summarized_history и присваиваем ей пустую строку\n",
    "        summarized_history = \"\"\n",
    "    if len(question_history) > 0: # self.\n",
    "        summarized_history = \"Вот краткий обзор предыдущего диалога: \" + summarize_questions([q + ' ' + (a if a is not None else '') for q, a in question_history]) # self. # await self. # self.\n",
    "    # Соединяем суммаризированный текст с новым вопросом пользователя\n",
    "    input_text = summarized_history + \"\\n\\nТекущий вопрос: \" + topic # self. # self.\n",
    "    # -----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_system},\n",
    "        {\"role\": \"user\", \"content\": \"Какой адрес вашего сайта?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Адрес нашего сайта: https://redmond.company\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Ответь на вопрос клиента. Не упоминай документ с информацией для ответа клиенту в ответе. Документ с информацией для ответа клиенту: {relevant_chunks}\\n\\nВопрос клиента: \\n{input_text}\"},\n",
    "    ]\n",
    "    # print(\"📡 OpenAI: messages, отправляемый в LLM: \\n\", messages)\n",
    "\n",
    "    if verbose:\n",
    "        print('\\n ===========================================: ')\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", # \"gpt-4o\" / \"gpt-4-0613\" / \"gpt-3.5-turbo\"\n",
    "        messages=messages,\n",
    "        temperature=0.4\n",
    "    )\n",
    "\n",
    "    answer = completion.choices[0].message['content']\n",
    "    # print(\"\\n***\\n\\n📢 Ответ от llm: \", answer, \"\\n\")\n",
    "    # Дополняем историю\n",
    "    question_history.append((input_text, answer if answer is not None else '')) # self. # self.\n",
    "    print(f\"История на выходе: {question_history}\")\n",
    "    # return answer, relevant_chunks, db_Availability\n",
    "    return completion.choices[0].message.content, relevant_chunks, db_Availability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - LOGIC FUN SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def answer_run_2_sum(question:str):\n",
    "#     # Функция чтения Promts\n",
    "#     def get_environment_value(file_path, name_key):\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             config = yaml.safe_load(file)\n",
    "#             return config.get(name_key)\n",
    "#     # Чтение значений ключа\n",
    "#     file_path = \"PROJECT/PROMTS/promts.yml\"\n",
    "#     system_mult_ = get_environment_value(file_path, \"system_mult\") # self.\n",
    "#     system_shop_ = get_environment_value(file_path, \"system_shop\") # self.\n",
    "#     system_cont_ = get_environment_value(file_path, \"system_cont\") # self.\n",
    "    \n",
    "#     print(f\"\"\"****************************************\"\"\")\n",
    "#     print(f'{bcolors256.underline()}    ❓ Вопрос пользователя:  {bcolors256.bg(11)}{bcolors256.fg(0)}{bcolors256.bold()}{question}{bcolors256.RESET} ')\n",
    "    \n",
    "#     sub_questions = question #  question_clusterizer(question)\n",
    "#     # print(f'    Подвопросов: {len(sub_questions)}')\n",
    "#     # print(f'    🔶 Подвопросы в вопросе пользователя: {bcolors256.bold()}  {sub_questions} {bcolors256.RESET}')\n",
    "    \n",
    "\n",
    "#     for question in sub_questions:\n",
    "#         print(f'\\n    ---\\n    Обработка вопроса:  {bcolors256.bg(20)}{bcolors256.fg(11)}{bcolors256.bold()}  {question} {bcolors256.RESET}')\n",
    "#         analitix = retriever_gpt_tems(question)\n",
    "        \n",
    "#         # ответ\n",
    "#         if analitix == \"Мультиварка\":\n",
    "#             print(f\"\\n    Тема вопроса: {analitix}\")\n",
    "#             db_name = retriever_gpt_model(question)\n",
    "#             print(f\"    Определилась модель для ответа: {db_name}\")\n",
    "#             path_db_faiss_mult = \"PROJECT/DATA/DB_FAISS\"\n",
    "#             answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_mult_, path_db_faiss_mult, question, db_name)\n",
    "#             print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#             print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#             print(f\"    База найдена: {db_Availability}\")\n",
    "#             sub_questions=[]\n",
    "                    \n",
    "#         elif analitix == \"Адрес\":\n",
    "#             print(f\"    Тема вопроса: {analitix}\")\n",
    "#             print(\"    Запрос адреса магазина\")\n",
    "#             path_db_faiss_shop = \"PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "#             db_name_shop = \"data_google_olther\"\n",
    "#             answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_shop_, path_db_faiss_shop, question, db_name_shop)\n",
    "#             print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#             print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#             sub_questions=[]\n",
    "        \n",
    "#         else:\n",
    "#             print(\"    Контактная информация\")\n",
    "#             print(f\"    Тема вопроса: {analitix}\")\n",
    "#             path_db_faiss_cont = \"PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "#             db_name_contact = \"data_google_contacts\"\n",
    "#             answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_cont_, path_db_faiss_cont, question, db_name_contact)\n",
    "#             print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "#             print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "#             sub_questions=[]\n",
    "            \n",
    "#     print(f\"\"\"\\n\\n****************************************\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_run_2_sum(question:str):\n",
    "    # Функция чтения Promts\n",
    "    def get_environment_value(file_path, name_key):\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            return config.get(name_key)\n",
    "    # Чтение значений ключа\n",
    "    file_path = \"PROJECT/PROMTS/promts.yml\"\n",
    "    system_mult_ = get_environment_value(file_path, \"system_mult\") # self.\n",
    "    system_shop_ = get_environment_value(file_path, \"system_shop\") # self.\n",
    "    system_cont_ = get_environment_value(file_path, \"system_cont\") # self.\n",
    "    \n",
    "    print(f\"\"\"****************************************\"\"\")\n",
    "    print(f'{bcolors256.underline()}    ❓ Вопрос пользователя:  {bcolors256.bg(11)}{bcolors256.fg(0)}{bcolors256.bold()}{question}{bcolors256.RESET} ')\n",
    "    \n",
    "    sub_questions = question #  question_clusterizer(question)\n",
    "    # print(f'    Подвопросов: {len(sub_questions)}')\n",
    "    # print(f'    🔶 Подвопросы в вопросе пользователя: {bcolors256.bold()}  {sub_questions} {bcolors256.RESET}')\n",
    "    \n",
    "\n",
    "    # for question in sub_questions:\n",
    "    print(f'\\n    ---\\n    Обработка вопроса:  {bcolors256.bg(20)}{bcolors256.fg(11)}{bcolors256.bold()}  {question} {bcolors256.RESET}')\n",
    "    analitix = retriever_gpt_tems(question)\n",
    "    \n",
    "    # ответ\n",
    "    if analitix == \"Мультиварка\":\n",
    "        print(f\"\\n    Тема вопроса: {analitix}\")\n",
    "        db_name = retriever_gpt_model(question)\n",
    "        print(f\"    Определилась модель для ответа: {db_name}\")\n",
    "        path_db_faiss_mult = \"PROJECT/DATA/DB_FAISS\"\n",
    "        answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_mult_, path_db_faiss_mult, question, db_name)\n",
    "        print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "        print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "        print(f\"    База найдена: {db_Availability}\")\n",
    "        sub_questions=[]\n",
    "                \n",
    "    elif analitix == \"Адрес\":\n",
    "        print(f\"    Тема вопроса: {analitix}\")\n",
    "        print(\"    Запрос адреса магазина\")\n",
    "        path_db_faiss_shop = \"PROJECT/DATA/DB_FAISS_OLTHER\"\n",
    "        db_name_shop = \"data_google_olther\"\n",
    "        answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_shop_, path_db_faiss_shop, question, db_name_shop)\n",
    "        print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "        print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "        sub_questions=[]\n",
    "    \n",
    "    else:\n",
    "        print(\"    Контактная информация\")\n",
    "        print(f\"    Тема вопроса: {analitix}\")\n",
    "        path_db_faiss_cont = \"PROJECT/DATA/DB_FAISS_CONTACTS\"\n",
    "        db_name_contact = \"data_google_contacts\"\n",
    "        answer, relevant_chunks_0, db_Availability = answer_oai_1_sum(system_cont_, path_db_faiss_cont, question, db_name_contact)\n",
    "        print(f'{bcolors256.underline()}    📢 Ответ LLM: {bcolors256.bg(76)}{bcolors256.fg(17)}{bcolors256.bold()} {answer} {bcolors256.RESET}')\n",
    "        print(f'    -Чанки:    {bcolors256.bg(2)}{bcolors256.fg(17)} {relevant_chunks_0} {bcolors256.RESET}')\n",
    "        sub_questions=[]\n",
    "            \n",
    "    print(f\"\"\"\\n\\n****************************************\"\"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### +++ RUN DIALOG SUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_questions=[]\n",
    "\n",
    "summarized_history = \"\" # self.\n",
    "question_history = [] # self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вопрос из списка: Сколько программ у RMC-03 и у RMC-28?\n",
      "****************************************\n",
      "\u001b[4m    ❓ Вопрос пользователя:  \u001b[48;5;11m\u001b[38;5;0m\u001b[1mСколько программ у RMC-03 и у RMC-28?\u001b[0m \n",
      "\n",
      "    ---\n",
      "    Обработка вопроса:  \u001b[48;5;20m\u001b[38;5;11m\u001b[1m  Сколько программ у RMC-03 и у RMC-28? \u001b[0m\n",
      "\n",
      "    Тема вопроса: Мультиварка\n",
      "    Определилась модель для ответа: none\n",
      "История на входе: []\n",
      "История на выходе: [('\\n\\nТекущий вопрос: Сколько программ у RMC-03 и у RMC-28?', 'У мультиварки RMC-03 20 программ, а у мультиварки RMC-28 50 программ.')]\n",
      "\u001b[4m    📢 Ответ LLM: \u001b[48;5;76m\u001b[38;5;17m\u001b[1m У мультиварки RMC-03 20 программ, а у мультиварки RMC-28 50 программ. \u001b[0m\n",
      "    -Чанки:    \u001b[48;5;2m\u001b[38;5;17m [] \u001b[0m\n",
      "    База найдена: False\n",
      "\n",
      "\n",
      "****************************************\n",
      "Вопрос из списка: Сколько они стоят?\n",
      "****************************************\n",
      "\u001b[4m    ❓ Вопрос пользователя:  \u001b[48;5;11m\u001b[38;5;0m\u001b[1mСколько они стоят?\u001b[0m \n",
      "\n",
      "    ---\n",
      "    Обработка вопроса:  \u001b[48;5;20m\u001b[38;5;11m\u001b[1m  Сколько они стоят? \u001b[0m\n",
      "\n",
      "    Тема вопроса: Мультиварка\n",
      "    Определилась модель для ответа: none\n",
      "История на входе: [('\\n\\nТекущий вопрос: Сколько программ у RMC-03 и у RMC-28?', 'У мультиварки RMC-03 20 программ, а у мультиварки RMC-28 50 программ.')]\n",
      "История на выходе: [('\\n\\nТекущий вопрос: Сколько программ у RMC-03 и у RMC-28?', 'У мультиварки RMC-03 20 программ, а у мультиварки RMC-28 50 программ.'), ('Вот краткий обзор предыдущего диалога: Поняла, у мультиварки RMC-03 20 программ, а у мультиварки RMC-28 50 программ. Если у вас есть еще вопросы по этим моделям, дайте знать!\\n\\nТекущий вопрос: Сколько они стоят?', 'Цена мультиварки RMC-03 составляет 4990 рублей, а мультиварки RMC-28 - 8990 рублей.')]\n",
      "\u001b[4m    📢 Ответ LLM: \u001b[48;5;76m\u001b[38;5;17m\u001b[1m Цена мультиварки RMC-03 составляет 4990 рублей, а мультиварки RMC-28 - 8990 рублей. \u001b[0m\n",
      "    -Чанки:    \u001b[48;5;2m\u001b[38;5;17m [] \u001b[0m\n",
      "    База найдена: False\n",
      "\n",
      "\n",
      "****************************************\n"
     ]
    }
   ],
   "source": [
    "questions = [\"Сколько программ у RMC-03 и у RMC-28?\",\n",
    "             \"Сколько они стоят?\"]\n",
    "\n",
    "        #    \"Сколько она стоит?\",\n",
    "        #    \"Сколько у неё программ\",\n",
    "        #    \"а у rmc-28\",\n",
    "        #    \"как вас найти?\",\n",
    "        #    \"а позвонить?\",\n",
    "for question  in questions:\n",
    "    print(f\"Вопрос из списка: {question}\")\n",
    "    answer = answer_run_2_sum(question)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - формирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пары (ключ, значение):\n",
      "\n",
      "КЛЮЧ: question, ЗНАЧЕНИЕ: Вопрос пользователя\n",
      "КЛЮЧ: answer, ЗНАЧЕНИЕ: Ответ LLM\n",
      "КЛЮЧ: boolean, ЗНАЧЕНИЕ: True\n",
      "КЛЮЧ: activation, ЗНАЧЕНИЕ: request\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "def create_json():\n",
    "    # Формируем данные\n",
    "    data_json = {\n",
    "        \"question\": \"Вопрос пользователя\",\n",
    "        \"answer\": \"Ответ LLM\",\n",
    "        \"boolean\": True,\n",
    "        \"activation\": \"request\" # on / off\n",
    "    }\n",
    "\n",
    "    # Записываем данные в файл\n",
    "    with open('data.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_json, f, ensure_ascii=False, indent=4)\n",
    "    return data_json\n",
    "\n",
    "data_json_ = create_json()\n",
    "\n",
    "\n",
    "# Читаем данные из полученного файла\n",
    "with open('data.json', 'r', encoding='utf-8') as f:\n",
    "    data_json = json.load(f)\n",
    "# Получение всех пар (ключ, значение)\n",
    "items = data_json.items()\n",
    "print(\"\\nПары (ключ, значение):\\n\")\n",
    "for key, value in items:\n",
    "    print(f\"КЛЮЧ: {key}, ЗНАЧЕНИЕ: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - изменение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "change_data = {\n",
    "    \"question\": 150,\n",
    "    \"answer\": \"Привет\",\n",
    "    \"boolean\": True,\n",
    "    \"activation\": \"on\"\n",
    "}\n",
    "\n",
    "def change_json(file_path_json: str, change_data: dict):\n",
    "    # Читаем данные из файла\n",
    "    with open(file_path_json, 'r', encoding='utf-8') as f:\n",
    "        data_json = json.load(f)\n",
    "    \n",
    "    # Вносим изменения\n",
    "    data_json[\"question\"] = change_data.get(\"question\", data_json.get(\"question\"))\n",
    "    data_json[\"answer\"] = change_data.get(\"answer\", data_json.get(\"answer\"))\n",
    "    data_json[\"boolean\"] = change_data.get(\"boolean\", data_json.get(\"boolean\"))\n",
    "    data_json[\"activation\"] = change_data.get(\"activation\", data_json.get(\"activation\"))\n",
    "    \n",
    "    # Записываем измененные данные обратно в файл\n",
    "    with open(file_path_json, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data_json, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Пример использования функции\n",
    "change_json('data.json', change_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - чтение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Пары (ключ, значение):\n",
      "\n",
      "КЛЮЧ: question, ЗНАЧЕНИЕ: 150\n",
      "КЛЮЧ: answer, ЗНАЧЕНИЕ: Привет\n",
      "КЛЮЧ: boolean, ЗНАЧЕНИЕ: True\n",
      "КЛЮЧ: activation, ЗНАЧЕНИЕ: on\n"
     ]
    }
   ],
   "source": [
    "# Читаем данные из полученного файла\n",
    "with open('data.json', 'r', encoding='utf-8') as f:\n",
    "    data_json = json.load(f)\n",
    "# Получение всех пар (ключ, значение)\n",
    "items = data_json.items()\n",
    "print(\"\\nПары (ключ, значение):\\n\")\n",
    "for key, value in items:\n",
    "    print(f\"КЛЮЧ: {key}, ЗНАЧЕНИЕ: {value}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
